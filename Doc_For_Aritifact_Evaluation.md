

- [Setup \&\& Configure](#setup--configure)
- [Evaluation](#evaluation)
  - [0. Minimal Running Example](#0-minimal-running-example)
  - [1. Specifcation Generation (Section VII.A).](#1-specifcation-generation-section-viia)
    - [1.0 Minimal Running](#10-minimal-running)
    - [1.1 Normal Test For Specfication Generation](#11-normal-test-for-specfication-generation)
  - [2. Bug Detection (Section VII.B).](#2-bug-detection-section-viib)
    - [2.0 Minimal Running For Bug Detection](#20-minimal-running-for-bug-detection)
    - [2.1 NormalTest For Bug Detection](#21-normaltest-for-bug-detection)
  - [3. Utilizebility of API Aritifacts (Section VII.D).](#3-utilizebility-of-api-aritifacts-section-viid)
  - [4. Compared with related work. (Section VII C.)](#4-compared-with-related-work-section-vii-c)


## Setup && Configure
Please refer to [INSTALL](./INSTALL.md) for installation and preparation.


In our evaluation, we used a 64-bit Ubuntu 22.04 system with 503GB of memory, powered by an Intel(R) Xeon(R) Gold 5218R CPU @ 2.10GHz with 79 processors.
APISpecGen works on standard machines and does not require significant memory overhead.

We recommend using multithreading to speed up the evaluation process. By default, 48 threads are used, but without multithreading, the process may take significantly longer. You can adjust the `num_threads` setting in the `config.cfg` file according to your needs. 

The execution time for the evaluation depends on the performance of the machine used. To avoid unexpectedly long evaluation times, you can limit the `max_depth` (default is 10) in the `script/1.specification_extraction.sh` to a smaller value (such as 1 or 2) during the specification generation phase. This will allow you to test the evaluation and estimate the time required.


## Evaluation
In the evaluation, we provided a minimal running example for quick test. Then we provide the evalution that shown in the paper.

### 0. Minimal Running Example
This is related to the working example that displayed in the paper (as shown below). 

- Please follow the [Specification Generation for working example](#10-minimal-running), which generates the shown specifcation (`nfc_get_device, nfc_put_device, `retval`).

- Follow the [Bug detection for working example](#20-minimal-running-for-bug-detection), which detects the `nfc_genl_vendor_cmd` function as buggy.




<img src=./assets/APISpecGen-working-example.png#pic_center width=60% />




### 1. Specifcation Generation (Section VII.A).

#### 1.0 Minimal Running 
- **[Intro]** Perform specfication progation analysis for a seed with iteration set to 2.
- **[Run]** `./script/0.quick_spec_generate.sh `
- **[Results]** 
The generated specification saved to `GeneratedSpecs/linux_get_device_1_generated_specs.json`
The reference data is `ReferenceData/LinuxKernel/linux_get_device_1_generated_specs.json`
Below is a generated specifcation example
```shell
{
  "API": "nfc_get_device", // the inferred API
  "SecOp": "nfc_put_device",// the inferred post-operation for the API     
  "usageCount": 21, // the usage times that follows the specifcation in the programs
  "depth": 2, // the propogation depth 
  "API_path": "get_device->class_find_device->nfc_get_device", // The API's propogation chain 
  "var_path": "arg->retval->retval" // the critical variable's propogation chain 
},
```
- **[Execution time]** 
```
real    0m23.331s
user    12m19.762s
sys     12m35.620s
```

#### 1.1 Normal Test For Specfication Generation
- **[Intro]** Generate specifcations use the given six seed specifcations.  
- **[Run]** `./script/1.specification_generation.sh`   
- **[Result]** The specifications generated by different seed API is saved to `linux_{seedAPI}_{max_depth}_generated_specs.json` in DIR `SpecGeneration/Data/GeneratedSpec` represtively. Each specifcation follow the format introduce above. For reference, we provide the generated specifications in `SpecGeneration/Data/ReferenceData`. Due to multiprocessing, the generated data may not match exactly. Nevertheless, the conclusions drawn from the data remain consistent.

Run `python SpecGeneration/summarize_spec_results.py` for statical analysis. 
By default, it use the reference data for statical analysis, which doesn't require to finish the specifcation generation yourself.
if you want to use the generated data for statical analysis, Run `python SpecGeneration/summarize_spec_results.py True`
Besides, You can config the variable `depth` and the `seed_apis` for any data you obtained.

Example output is shown below:
```shell
API Spec Count Summary:
              API  Specs Count
       get_device          831
device_initialize           55
   try_module_get           75
          kmalloc         1332
          kstrdup          121
          ERR_PTR         6377

Total Specs: 8791
```

We updated some code logic in the artifacts, which results in slight differences in the data compared to what is presented in the paper. And the results support the main claim. 

Below, we provide the execution time in our evaluations for reference. The data is saved to `SpecGeneration/Data/ReferenceData` 
| SeedAPI           | Depth | Time                                         |
| ----------------- | ----- | -------------------------------------------- |
| get_device        | 10    | real: 48m, user: 1246m, sys: 871m            |
| kstrdup           | 10    | real: 11m, user: 486m, sys: 309m             |
| kmalloc           | 10    | real: 43m, user: 1767m, sys: 1251m           |
| device_initialize | 10    | real: 2m, user: 85m, sys: 57m                |
| try_module_get    | 10    | real: 2m, user: 86m, sys: 61m                |
| ERR_PTR           | 10    | real: 14m, user:460m sys:457m                |
| **Total Time**    | -     | real: 120 min; user: 4130 min, sys: 3006 min |




### 2. Bug Detection (Section VII.B).

#### 2.0 Minimal Running For Bug Detection
- **[Intro]** Perform quick test for bug detection using one generated specification [obtained from specifcation generation for working example](#10-minimal-running). Use the specifcation generated from step (nfc_get_device, nfc_put_device,retval) to detect bugs. 
- **[Run]** `./script/0.1.quick_bug_detection_for_test.sh` 
- **[Results]** 
The script prints out the detected potential bugs. This includes the buggy function `nfc_genl_vendor_cmd` displayed in the paper.
The output example: 
```shell
[checked report] nfc_genl_se_io may lack post-operation (['nfc_put_device']) for nfc_get_device
[checked report] nfc_genl_vendor_cmd may lack post-operation (['nfc_put_device']) for nfc_get_device
```
Manual confirm that reports are true bugs.
- **[Execution Time]**
```shell
real    0m1.575s
user    0m6.052s
sys     0m8.942s
```
#### 2.1 NormalTest For Bug Detection
- **[Intro]** Use generated specifcations to detect new bugs in the Linux kernel. To facilates evaluation, we provided a set of specifcations that related to detected bugs for valiatation. All the used specifications are previously generated by APISpecGen.

- **[Run]** `./script/2.bug_detection.sh`

- **[Results]** Using the specifcations, APISpecGen detects hundreads of new bugs in the Linux kernel. During the detection, the bug reports will be continuously logged into the file `BugDetection/data/bug_report.csv`. 

- The bug report example, which include the buggy func and the corresponding specifcations (`main_api,sec_op,var_type`).
```csv
repo_name,buggy_func,main_api,sec_op,var_type,var,scope,violated_path_num
kernel,nfc_genl_vendor_cmd,nfc_get_device,nfc_put_device,retval,dev,Local,6
```
It often requires to validate whether the reported bugs are true. 
In the aritifacts, we provide a list of true bugs we confirmed in the Linux kernel v5.16 for automatically confirm the main claim that the generated specifications can detect numerous new bugs. After the detection, you may run `python script/ResultsCheck/check_bug_detect.py` to check that the true bugs are detected by the APISpecGen. 

If you want to manually confirm the bug reports, you may use the script (`BugDetection/report_ranker.py`) to rank the reports, with reports are the front are more likey to be true bugs. (Run `python BugDetection/report_ranker.py --file BugDetection/data/bug_report.csv`)

Besides, the generated specifications can be used to detect bugs across different versions of the program. APISpecGen has detected new bugs in the latest version of the Linux kernel, and we are currently working on addressing these newly detected bugs. The bug reports from the latest version differ from those detected in v5.16. But this does not affect our main claim.


### 3. Utilizebility of API Aritifacts (Section VII.D).
- **[Intro]** Use the generated specifications to evaluate the usability of API artifacts (including API documentation, API names, and API usage) for specification extraction. We use paired specifications for evaluation because these artifacts are commonly used to extract such specifications.
- **[Run]** `./script/3.API_aritifact_analysis.sh`
- **[Note]** We provide the previously generated specifications for analysis. Alternatively, you can specify the `spec_file` in `APIAritifactEval/APIAritifactEval.py`. The results should be similar.
- **[Results]**  The analysis data reveals that API artifacts have significant limitations in specification extraction. 
An example output is shown below:
```shell
[API Name Analysis]: 15.96% APIs do not contain the informative subwords (verbs).
[API Usage Analysis]: 93.80% API pairs usage occur less than 10 times, 88.07% API pairs usage occur less than 5 times.
[API Doc Analysis]: 95.00% of specifcations are not mentioned in documents For all APIs pairs.
[API Doc Analysis]: 76.31% of specifcations are not mentioned in documents for those API having docs
```

### 4. Compared with related work. (Section VII C.)
In the paper, we compare APISpecGen with SinkFiner, APHP, Advance, and IPPO.

In the artifacts, we provide the specifications collected from SinkFiner and APHP, located in `ComparedWithRelatedWork/RelatedWorkData`, which are used to conclude the comparative results.

For Advance, we reference the API doc for specfication extraction to obtain the results.

For IPPO, we directly run it to conclude the results.


